{"cells":[{"cell_type":"markdown","metadata":{"id":"psn7MZqCKACe"},"source":["# install & import"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227775,"status":"ok","timestamp":1717085717758,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"},"user_tz":-60},"id":"XQNW6BQiJSVF","outputId":"9fee01dd-e9c8-48ee-95e1-d114a0d6d8c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.2.1\n","  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m870.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Collecting triton==2.2.0 (from torch==2.2.1)\n","  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1) (1.3.0)\n","Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.0\n","    Uninstalling triton-2.3.0:\n","      Successfully uninstalled triton-2.3.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.0+cu121\n","    Uninstalling torch-2.3.0+cu121:\n","      Successfully uninstalled torch-2.3.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.2.1 which is incompatible.\n","torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.1 which is incompatible.\n","torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torch-2.2.1 triton-2.2.0\n"]}],"source":["!pip install torch==2.2.1"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43171,"status":"ok","timestamp":1717085760909,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"},"user_tz":-60},"id":"dy1_7mh1KACt","outputId":"3ce8be6e-62c1-425b-f5c4-0cfafce059ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.5.3\n"]}],"source":["!pip install faiss-gpu\n","#!pip install pyg-lib -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n","!pip install torch-geometric"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5h8dLDdYKACv","executionInfo":{"status":"ok","timestamp":1717085772229,"user_tz":-60,"elapsed":11361,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["import torch\n","from transformers import BertTokenizer, BertModel\n","from torch_geometric.data import HeteroData\n"]},{"cell_type":"markdown","metadata":{"id":"8aqRXaQpMODX"},"source":["# graph creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N-M4bfx1J6ur"},"outputs":[],"source":["\n","def create_hetero_data(user_file, job_file, app_file):\n","    def get_bert_embeddings(texts):\n","        if isinstance(texts, str):\n","            texts = [texts]  # Ensure texts is a list\n","        embeddings = []\n","        batch_size = 256  # Define batch size\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","        model = BertModel.from_pretrained('bert-base-uncased').to(device)\n","        for i in range(0, len(texts), batch_size):\n","            batch_texts = texts[i:i+batch_size]\n","            encoding = tokenizer.batch_encode_plus(\n","                batch_texts,\n","                padding=True,\n","                truncation=True,\n","                return_tensors='pt',\n","                add_special_tokens=True\n","            )\n","            input_ids = encoding['input_ids'].to(device)\n","            attention_mask = encoding['attention_mask'].to(device)\n","            with torch.no_grad():\n","                outputs = model(input_ids, attention_mask=attention_mask)\n","                word_embeddings = outputs.last_hidden_state\n","                sentence_embedding = word_embeddings.mean(dim=1)\n","                embeddings.append(sentence_embedding)\n","            print(i)\n","        return torch.cat(embeddings, dim=0)\n","\n","    def load_node_csv(path, index_col, encoders=None, **kwargs):\n","        print(\"load node\")\n","        df = pd.read_csv(path, index_col=index_col, **kwargs)\n","        mapping = {index: i for i, index in enumerate(df.index.unique())}\n","        x = None\n","        if encoders is not None:\n","            xs = [encoder(df[col]) for col, encoder in encoders.items()]\n","            x = xs[0]\n","        return df, x, mapping\n","\n","    print(\"start\")\n","\n","    user_df, user_x, user_mapping = load_node_csv(user_file, index_col='userID', encoders={'text_emb': get_bert_embeddings})\n","    print(\"user mapping done\")\n","    job_df, job_x, job_mapping = load_node_csv(job_file, index_col='jobID', encoders={'text_emb': get_bert_embeddings})\n","    print(\"job mapping done\")\n","\n","    data = HeteroData()\n","\n","    # Add user nodes\n","    data['user'].num_nodes = len(user_mapping)\n","    data['user'].x = user_x\n","    data['user'].index = torch.tensor(list(user_mapping.keys()), dtype=torch.long)\n","\n","    # Add job nodes\n","    data['job'].num_nodes = len(job_mapping)\n","    data['job'].x = job_x\n","    data['job'].index = torch.tensor(list(job_mapping.keys()), dtype=torch.long)\n","\n","    # Add topic information\n","    user_topics = user_df['topic'].values\n","    job_topics = job_df['topic'].values\n","    data['user'].topic = torch.tensor(user_topics, dtype=torch.long)\n","    data['job'].topic = torch.tensor(job_topics, dtype=torch.long)\n","\n","    print(\"app start\")\n","    apps = pd.read_csv(app_file)\n","\n","    # Add edges between user and job nodes\n","    edge_index_user_job = torch.tensor([apps['userID'].map(user_mapping).values, apps['jobID'].map(job_mapping).values], dtype=torch.long)\n","    data['user', 'applies', 'job'].edge_index = edge_index_user_job\n","\n","    # Add labels for edges\n","    num_users = len(user_mapping)\n","    num_jobs = len(job_mapping)\n","    edge_label = torch.zeros((num_users, num_jobs), dtype=torch.long)\n","    edge_label[edge_index_user_job[0], edge_index_user_job[1]] = 1\n","    data['user', 'applies', 'job'].edge_label = edge_label[edge_index_user_job[0], edge_index_user_job[1]]\n","\n","    del apps\n","\n","    # Add edges between similar users\n","    user_topic_groups = user_df.groupby('topic').indices\n","    user_user_edges = []\n","    for topic, user_indices in user_topic_groups.items():\n","        for i, user_i in enumerate(user_indices):\n","            for j in user_indices[i + 1:]:\n","                user_user_edges.append([user_mapping[user_i], user_mapping[j]])\n","                user_user_edges.append([user_mapping[j], user_mapping[user_i]])\n","    data['user', 'similar_U', 'user'].edge_index = torch.tensor(user_user_edges, dtype=torch.long).t().contiguous()\n","\n","    del user_df\n","\n","    # Add edges between similar jobs\n","    job_topic_groups = job_df.groupby('topic').indices\n","    job_job_edges = []\n","    for topic, job_indices in job_topic_groups.items():\n","        for i, job_i in enumerate(job_indices):\n","            for j in job_indices[i + 1:]:\n","                job_job_edges.append([job_mapping[job_i], job_mapping[j]])\n","                job_job_edges.append([job_mapping[j], job_mapping[job_i]])\n","    data['job', 'similar_J', 'job'].edge_index = torch.tensor(job_job_edges, dtype=torch.long).t().contiguous()\n","\n","    del job_df\n","\n","    # Ensure the graph is undirected\n","    data = ToUndirected()(data)\n","\n","    return data\n"]},{"cell_type":"markdown","metadata":{"id":"kj-YciHk6U5p"},"source":["# new functions test"]},{"cell_type":"markdown","metadata":{"id":"dHx6iNoZlBOL"},"source":["## embed"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zWzCbwrElCbG","executionInfo":{"status":"ok","timestamp":1717085772230,"user_tz":-60,"elapsed":52,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def get_bert_embedding(text):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    model = BertModel.from_pretrained('bert-base-uncased').to(device)\n","\n","    encoding = tokenizer.encode_plus(\n","        text,\n","        padding=True,\n","        truncation=True,\n","        return_tensors='pt',\n","        add_special_tokens=True\n","    )\n","    input_ids = encoding['input_ids'].to(device)\n","    attention_mask = encoding['attention_mask'].to(device)\n","    with torch.no_grad():\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        word_embeddings = outputs.last_hidden_state\n","        sentence_embedding = word_embeddings.mean(dim=1)\n","\n","    return sentence_embedding.squeeze().cpu()"]},{"cell_type":"markdown","metadata":{"id":"4-wTQRPmM6Wu"},"source":["## create empty graph"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"bKphlK-76koL","executionInfo":{"status":"ok","timestamp":1717085772230,"user_tz":-60,"elapsed":48,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def create_empty_graph():\n","    data = HeteroData()\n","\n","    # Initialize user node\n","    data['user'].num_nodes = 0\n","    data['user'].x = torch.empty((0, 768))  # Adjust the shape to match the embedding size\n","    data['user'].topic = torch.empty((0,), dtype=torch.long)\n","    data['user'].index = torch.empty((0,), dtype=torch.long)\n","\n","    # Initialize job node\n","    data['job'].num_nodes = 0\n","    data['job'].x = torch.empty((0, 768))  # Adjust the shape to match the embedding size\n","    data['job'].topic = torch.empty((0,), dtype=torch.long)\n","    data['job'].index = torch.empty((0,), dtype=torch.long)\n","\n","    # Initialize edges and edge labels\n","    data['user', 'applies', 'job'].edge_index = torch.empty((2, 0), dtype=torch.long)\n","    data['user', 'applies', 'job'].edge_label = torch.empty((0,),dtype=torch.long)\n","    data['user', 'similar_U', 'user'].edge_index = torch.empty((2, 0), dtype=torch.long)\n","    data['job', 'similar_J', 'job'].edge_index = torch.empty((2, 0), dtype=torch.long)\n","    data['job', 'rev_applies', 'user'].edge_index = torch.empty((2, 0), dtype=torch.long)\n","    data['job', 'rev_applies', 'user'].edge_label = torch.empty((0,),dtype=torch.long)\n","\n","    return data"]},{"cell_type":"markdown","metadata":{"id":"onJckv8-6i7s"},"source":["## add"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"uNISCbzO6xOd","executionInfo":{"status":"ok","timestamp":1717085772231,"user_tz":-60,"elapsed":47,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def add_node_user(data, userID, text, topic):\n","    # Add user node\n","    new_index = data['user'].num_nodes\n","    data['user'].num_nodes += 1\n","    new_embedding = get_bert_embedding(text)\n","    if data['user'].x is None:\n","        data['user'].x = new_embedding.unsqueeze(0)\n","    else:\n","        data['user'].x = torch.cat([data['user'].x, new_embedding.unsqueeze(0)], dim=0)\n","    data['user'].topic = torch.cat([data['user'].topic, torch.tensor([topic], dtype=torch.long)], dim=0)\n","    data['user'].index = torch.cat([data['user'].index, torch.tensor([userID], dtype=torch.long)], dim=0)\n","\n","    # Create edges with similar users\n","    user_indices = (data['user'].topic == topic).nonzero(as_tuple=True)[0]\n","    new_edges = []\n","    for idx in user_indices:\n","        if idx != new_index:\n","            new_edges.append([new_index, idx.item()])\n","            new_edges.append([idx.item(), new_index])\n","\n","    if new_edges:\n","        new_edges = torch.tensor(new_edges, dtype=torch.long).t().contiguous()\n","        if data['user', 'similar_U', 'user'].edge_index is None:\n","            data['user', 'similar_U', 'user'].edge_index = new_edges\n","        else:\n","            data['user', 'similar_U', 'user'].edge_index = torch.cat([data['user', 'similar_U', 'user'].edge_index, new_edges], dim=1)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"piH3Bc3N8LuZ","executionInfo":{"status":"ok","timestamp":1717085772231,"user_tz":-60,"elapsed":44,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def add_node_job(data, jobID, text, topic):\n","    # Add job node\n","    new_index = data['job'].num_nodes\n","    data['job'].num_nodes += 1\n","    new_embedding = get_bert_embedding(text)\n","    if data['job'].x is None:\n","        data['job'].x = new_embedding.unsqueeze(0)\n","    else:\n","        data['job'].x = torch.cat([data['job'].x, new_embedding.unsqueeze(0)], dim=0)\n","    data['job'].topic = torch.cat([data['job'].topic, torch.tensor([topic], dtype=torch.long)], dim=0)\n","    data['job'].index = torch.cat([data['job'].index, torch.tensor([jobID], dtype=torch.long)], dim=0)\n","\n","    # Create edges with similar jobs\n","    job_indices = (data['job'].topic == topic).nonzero(as_tuple=True)[0]\n","    new_edges = []\n","    for idx in job_indices:\n","        if idx != new_index:\n","            new_edges.append([new_index, idx.item()])\n","            new_edges.append([idx.item(), new_index])\n","\n","    if new_edges:\n","        new_edges = torch.tensor(new_edges, dtype=torch.long).t().contiguous()\n","        if data['job', 'similar_J', 'job'].edge_index is None:\n","            data['job', 'similar_J', 'job'].edge_index = new_edges\n","        else:\n","            data['job', 'similar_J', 'job'].edge_index = torch.cat([data['job', 'similar_J', 'job'].edge_index, new_edges], dim=1)"]},{"cell_type":"markdown","metadata":{"id":"io1Pt_0S6Z8R"},"source":["## delete"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"OATwIgZW6XF-","executionInfo":{"status":"ok","timestamp":1717085772563,"user_tz":-60,"elapsed":23,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def delete_node_user(data, userID):\n","    # Find the index of the userID in the 'user' node index tensor\n","    idx = (data['user'].index == userID).nonzero(as_tuple=True)[0]\n","    if idx.numel() > 0:\n","        idx = idx.item()  # Convert tensor to a scalar index\n","\n","        # Update user attributes by removing the node\n","        data['user'].x = torch.cat([data['user'].x[:idx], data['user'].x[idx+1:]], dim=0)\n","        data['user'].topic = torch.cat([data['user'].topic[:idx], data['user'].topic[idx+1:]], dim=0)\n","        data['user'].index = torch.cat([data['user'].index[:idx], data['user'].index[idx+1:]], dim=0)\n","        data['user'].num_nodes -= 1\n","\n","        # Update edges for 'user_applies_job' relationship\n","        edges_to_remove = (data['user', 'applies', 'job'].edge_index[0] == idx).nonzero(as_tuple=True)[0]\n","        keep_edges = torch.ones(data['user', 'applies', 'job'].edge_index.size(1), dtype=torch.bool)\n","        keep_edges[edges_to_remove] = False\n","        data['user', 'applies', 'job'].edge_index = data['user', 'applies', 'job'].edge_index[:, keep_edges]\n","        data['user', 'applies', 'job'].edge_label = data['user', 'applies', 'job'].edge_label[keep_edges]\n","\n","        # Decrement indices in 'user_applies_job'\n","        data['user', 'applies', 'job'].edge_index[0] -= (data['user', 'applies', 'job'].edge_index[0] > idx).int()\n","\n","        # Update edges for 'job_rev_applies_user' relationship\n","        edges_to_remove = (data['job', 'rev_applies', 'user'].edge_index[1] == idx).nonzero(as_tuple=True)[0]\n","        keep_edges = torch.ones(data['job', 'rev_applies', 'user'].edge_index.size(1), dtype=torch.bool)\n","        keep_edges[edges_to_remove] = False\n","        data['job', 'rev_applies', 'user'].edge_index = data['job', 'rev_applies', 'user'].edge_index[:, keep_edges]\n","        data['job', 'rev_applies', 'user'].edge_label = data['job', 'rev_applies', 'user'].edge_label[keep_edges]\n","\n","        # Decrement indices in 'job_rev_applies_user'\n","        data['job', 'rev_applies', 'user'].edge_index[1] -= (data['job', 'rev_applies', 'user'].edge_index[1] > idx).int()\n","\n","        # Update edges for 'user_similar_user' relationship\n","        edges_to_remove = ((data['user', 'similar_U', 'user'].edge_index[0] == idx) | (data['user', 'similar_U', 'user'].edge_index[1] == idx)).nonzero(as_tuple=True)[0]\n","        keep_edges = torch.ones(data['user', 'similar_U', 'user'].edge_index.size(1), dtype=torch.bool)\n","        keep_edges[edges_to_remove] = False\n","        data['user', 'similar_U', 'user'].edge_index = data['user', 'similar_U', 'user'].edge_index[:, keep_edges]\n","\n","        # Decrement indices in 'user_similar_user'\n","        data['user', 'similar_U', 'user'].edge_index[0] -= (data['user', 'similar_U', 'user'].edge_index[0] > idx).int()\n","        data['user', 'similar_U', 'user'].edge_index[1] -= (data['user', 'similar_U', 'user'].edge_index[1] > idx).int()\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"igK7mhi36b-D","executionInfo":{"status":"ok","timestamp":1717085772564,"user_tz":-60,"elapsed":22,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def delete_node_job(data, jobID):\n","    # Find the index of the jobID in the 'job' node index tensor\n","    idx = (data['job'].index == jobID).nonzero(as_tuple=True)[0]\n","    if idx.numel() > 0:\n","        idx = idx.item()  # Convert tensor to a scalar index\n","\n","        # Update job attributes by removing the node\n","        data['job'].x = torch.cat([data['job'].x[:idx], data['job'].x[idx+1:]], dim=0)\n","        data['job'].topic = torch.cat([data['job'].topic[:idx], data['job'].topic[idx+1:]], dim=0)\n","        data['job'].index = torch.cat([data['job'].index[:idx], data['job'].index[idx+1:]], dim=0)\n","        data['job'].num_nodes -= 1\n","\n","        # Update edges for 'user_applies_job' relationship\n","        edges_to_remove = (data['user', 'applies', 'job'].edge_index[1] == idx).nonzero(as_tuple=True)[0]\n","        keep_edges = torch.ones(data['user', 'applies', 'job'].edge_index.size(1), dtype=torch.bool)\n","        keep_edges[edges_to_remove] = False\n","        data['user', 'applies', 'job'].edge_index = data['user', 'applies', 'job'].edge_index[:, keep_edges]\n","        data['user', 'applies', 'job'].edge_label = data['user', 'applies', 'job'].edge_label[keep_edges]\n","\n","        # Decrement indices in 'user_applies_job'\n","        data['user', 'applies', 'job'].edge_index[1] -= (data['user', 'applies', 'job'].edge_index[1] > idx).int()\n","\n","        # Update edges for 'job_rev_applies_user' relationship\n","        edges_to_remove = (data['job', 'rev_applies', 'user'].edge_index[0] == idx).nonzero(as_tuple=True)[0]\n","        keep_edges = torch.ones(data['job', 'rev_applies', 'user'].edge_index.size(1), dtype=torch.bool)\n","        keep_edges[edges_to_remove] = False\n","        data['job', 'rev_applies', 'user'].edge_index = data['job', 'rev_applies', 'user'].edge_index[:, keep_edges]\n","        data['job', 'rev_applies', 'user'].edge_label = data['job', 'rev_applies', 'user'].edge_label[keep_edges]\n","\n","        # Decrement indices in 'job_rev_applies_user'\n","        data['job', 'rev_applies', 'user'].edge_index[0] -= (data['job', 'rev_applies', 'user'].edge_index[0] > idx).int()\n","\n","        # Update edges for 'job_similar_job' relationship\n","        edges_to_remove = ((data['job', 'similar_J', 'job'].edge_index[0] == idx) | (data['job', 'similar_J', 'job'].edge_index[1] == idx)).nonzero(as_tuple=True)[0]\n","        keep_edges = torch.ones(data['job', 'similar_J', 'job'].edge_index.size(1), dtype=torch.bool)\n","        keep_edges[edges_to_remove] = False\n","        data['job', 'similar_J', 'job'].edge_index = data['job', 'similar_J', 'job'].edge_index[:, keep_edges]\n","\n","        # Decrement indices in 'job_similar_job'\n","        data['job', 'similar_J', 'job'].edge_index[0] -= (data['job', 'similar_J', 'job'].edge_index[0] > idx).int()\n","        data['job', 'similar_J', 'job'].edge_index[1] -= (data['job', 'similar_J', 'job'].edge_index[1] > idx).int()\n"]},{"cell_type":"markdown","metadata":{"id":"pEKuQSxt9BBD"},"source":["## modify"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"mghWuBQ19CnC","executionInfo":{"status":"ok","timestamp":1717085772564,"user_tz":-60,"elapsed":20,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def modify_node_user(data, userID, new_text, new_topic):\n","    # Find the index of the userID in the 'user' node index tensor\n","    idx = (data['user'].index == userID).nonzero(as_tuple=True)[0]\n","    if idx.numel() > 0:\n","        idx = idx.item()  # Convert tensor to a scalar index\n","\n","        # Update user attributes\n","        new_embedding = get_bert_embedding(new_text)\n","        data['user'].x[idx] = new_embedding\n","        data['user'].topic[idx] = new_topic\n","\n","        # Update edges for 'user_similar_user' relationship\n","        # Remove old edges\n","        edges_to_remove = ((data['user', 'similar_U', 'user'].edge_index[0] == idx) |\n","                           (data['user', 'similar_U', 'user'].edge_index[1] == idx)).nonzero(as_tuple=True)[0]\n","        keep_edges = torch.ones(data['user', 'similar_U', 'user'].edge_index.size(1), dtype=torch.bool)\n","        keep_edges[edges_to_remove] = False\n","        data['user', 'similar_U', 'user'].edge_index = data['user', 'similar_U', 'user'].edge_index[:, keep_edges]\n","\n","        # Create new edges based on the new topic\n","        user_indices = (data['user'].topic == new_topic).nonzero(as_tuple=True)[0]\n","        new_edges = []\n","        for user_idx in user_indices:\n","            if user_idx.item() != idx:\n","                new_edges.append([idx, user_idx.item()])\n","                new_edges.append([user_idx.item(), idx])\n","\n","        if new_edges:\n","            new_edges = torch.tensor(new_edges, dtype=torch.long).t().contiguous()\n","            if data['user', 'similar_U', 'user'].edge_index is None:\n","                data['user', 'similar_U', 'user'].edge_index = new_edges\n","            else:\n","                data['user', 'similar_U', 'user'].edge_index = torch.cat([data['user', 'similar_U', 'user'].edge_index, new_edges], dim=1)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Jy0oD_Yk-1Gv","executionInfo":{"status":"ok","timestamp":1717085772565,"user_tz":-60,"elapsed":19,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def modify_node_job(data, jobID, new_text, new_topic):\n","    # Find the index of the jobID in the 'job' node index tensor\n","    idx = (data['job'].index == jobID).nonzero(as_tuple=True)\n","    if idx[0].numel() > 0:\n","        idx = idx[0].item()  # Convert tensor to a scalar index\n","\n","        # Update job attributes\n","        new_embedding = get_bert_embedding(new_text)\n","        data['job'].x[idx] = new_embedding\n","        data['job'].topic[idx] = new_topic\n","\n","        # Update edges for 'job_similar_job' relationship\n","        # Remove old edges\n","        edges_to_remove = ((data['job', 'similar_J', 'job'].edge_index[0] == idx) |\n","                           (data['job', 'similar_J', 'job'].edge_index[1] == idx)).nonzero(as_tuple=True)[0]\n","        keep_edges = torch.ones(data['job', 'similar_J', 'job'].edge_index.size(1), dtype=torch.bool)\n","        keep_edges[edges_to_remove] = False\n","        data['job', 'similar_J', 'job'].edge_index = data['job', 'similar_J', 'job'].edge_index[:, keep_edges]\n","\n","        # Create new edges based on the new topic\n","        job_indices = (data['job'].topic == new_topic).nonzero(as_tuple=True)[0]\n","        new_edges = []\n","        for job_idx in job_indices:\n","            if job_idx.item() != idx:\n","                new_edges.append([idx, job_idx.item()])\n","                new_edges.append([job_idx.item(), idx])\n","\n","        if new_edges:\n","            new_edges = torch.tensor(new_edges, dtype=torch.long).t().contiguous()\n","            if data['job', 'similar_J', 'job'].edge_index is None:\n","                data['job', 'similar_J', 'job'].edge_index = new_edges\n","            else:\n","                data['job', 'similar_J', 'job'].edge_index = torch.cat([data['job', 'similar_J', 'job'].edge_index, new_edges], dim=1)\n"]},{"cell_type":"markdown","metadata":{"id":"VAqC_Tvn_fwj"},"source":["## add app"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Ji07KvGP_zJ_","executionInfo":{"status":"ok","timestamp":1717085772565,"user_tz":-60,"elapsed":18,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def add_edge_app(data, userID, jobID):\n","    # Find the index positions of userID and jobID in their respective node tensors\n","    user_index = (data['user'].index == userID).nonzero(as_tuple=True)\n","    job_index = (data['job'].index == jobID).nonzero(as_tuple=True)\n","\n","    if user_index[0].numel() > 0 and job_index[0].numel() > 0:\n","        user_index = user_index[0].item()\n","        job_index = job_index[0].item()\n","\n","        # Add edge between user and job with edge label 1\n","        data['user', 'applies', 'job'].edge_index = torch.cat([data['user', 'applies', 'job'].edge_index, torch.tensor([[user_index], [job_index]], dtype=torch.long)], dim=1)\n","        data['user', 'applies', 'job'].edge_label = torch.cat([data['user', 'applies', 'job'].edge_label, torch.tensor([1], dtype=torch.long)], dim=0)\n","\n","        # Add reverse edge between job and user (rev_applies) with edge label 1\n","        data['job', 'rev_applies', 'user'].edge_index = torch.cat([data['job', 'rev_applies', 'user'].edge_index, torch.tensor([[job_index], [user_index]], dtype=torch.long)], dim=1)\n","        data['job', 'rev_applies', 'user'].edge_label = torch.cat([data['job', 'rev_applies', 'user'].edge_label, torch.tensor([1], dtype=torch.long)], dim=0)\n"]},{"cell_type":"markdown","metadata":{"id":"SdgjHLgRDFhX"},"source":["## delete app"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"p9c14OFJC4vp","executionInfo":{"status":"ok","timestamp":1717085772566,"user_tz":-60,"elapsed":18,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def delete_app_edge(data, userID, jobID):\n","    # Find the index positions of userID and jobID in their respective node tensors\n","    user_index = (data['user'].index == userID).nonzero(as_tuple=True)\n","    job_index = (data['job'].index == jobID).nonzero(as_tuple=True)\n","\n","    if user_index[0].numel() > 0 and job_index[0].numel() > 0:\n","        user_index = user_index[0].item()\n","        job_index = job_index[0].item()\n","\n","        # Remove edge between user and job\n","        user_applies_job_edges = (data['user', 'applies', 'job'].edge_index[0] == user_index) & (data['user', 'applies', 'job'].edge_index[1] == job_index)\n","        user_applies_job_edges = user_applies_job_edges.nonzero(as_tuple=True)[0]\n","\n","        if user_applies_job_edges.numel() > 0:\n","            user_applies_job_edges = user_applies_job_edges.item()\n","\n","            data['user', 'applies', 'job'].edge_index = torch.cat([data['user', 'applies', 'job'].edge_index[:, :user_applies_job_edges], data['user', 'applies', 'job'].edge_index[:, user_applies_job_edges+1:]], dim=1)\n","            data['user', 'applies', 'job'].edge_label = torch.cat([data['user', 'applies', 'job'].edge_label[:user_applies_job_edges], data['user', 'applies', 'job'].edge_label[user_applies_job_edges+1:]], dim=0)\n","\n","        # Remove reverse edge between job and user (rev_applies)\n","        job_rev_applies_user_edges = (data['job', 'rev_applies', 'user'].edge_index[0] == job_index) & (data['job', 'rev_applies', 'user'].edge_index[1] == user_index)\n","        job_rev_applies_user_edges = job_rev_applies_user_edges.nonzero(as_tuple=True)[0]\n","\n","        if job_rev_applies_user_edges.numel() > 0:\n","            job_rev_applies_user_edges = job_rev_applies_user_edges.item()\n","\n","            data['job', 'rev_applies', 'user'].edge_index = torch.cat([data['job', 'rev_applies', 'user'].edge_index[:, :job_rev_applies_user_edges], data['job', 'rev_applies', 'user'].edge_index[:, job_rev_applies_user_edges+1:]], dim=1)\n","            data['job', 'rev_applies', 'user'].edge_label = torch.cat([data['job', 'rev_applies', 'user'].edge_label[:job_rev_applies_user_edges], data['job', 'rev_applies', 'user'].edge_label[job_rev_applies_user_edges+1:]], dim=0)\n"]},{"cell_type":"markdown","metadata":{"id":"9V224N-8Dc3H"},"source":["## recommend"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"_O6P2rwQDeSu","executionInfo":{"status":"ok","timestamp":1717085772566,"user_tz":-60,"elapsed":17,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"outputs":[],"source":["def recommend_top_k(user_id, data, model, k=10):\n","    # Find the index of the user in the 'user' node index tensor\n","    user_index = (data['user'].index == user_id).nonzero(as_tuple=True)[0]\n","    if user_index.numel() == 0:\n","        raise ValueError(f\"userID {user_id} not found in user nodes\")\n","\n","    user_index = user_index.item()\n","\n","    # Encode user and job features using the model\n","    encoded_data = model.encoder(data.x_dict, data.edge_index_dict)\n","\n","    # Find jobs that the user has interacted with\n","    user_interacted_jobs = data['user', 'applies', 'job'].edge_index[1][data['user', 'applies', 'job'].edge_index[0] == user_index]\n","\n","    # Get all job indices\n","    all_job_indices = torch.arange(data['job'].num_nodes)\n","\n","    # Remove jobs that the user has interacted with\n","    candidate_job_indices = all_job_indices[~torch.isin(all_job_indices, user_interacted_jobs)]\n","\n","    # Adjust k if it exceeds the number of candidate jobs\n","    k = min(k, len(candidate_job_indices))\n","\n","    # Create a tensor with the same length as candidate_job_indices, filled with user_index\n","    user_index_tensor = torch.full((len(candidate_job_indices),), user_index, dtype=torch.long)\n","\n","    # Calculate recommendation scores using model's decoder\n","    recommendation_scores = model.decoder(encoded_data, (user_index_tensor, candidate_job_indices))\n","\n","    # Extract top-k job indices with highest recommendation scores\n","    top_k_values, top_k_indices = torch.topk(recommendation_scores, k, largest=True, sorted=True)\n","    top_k_job_indices = candidate_job_indices[top_k_indices]\n","\n","    # Map job indices to their original IDs in data['job'].index\n","    top_k_job_ids = data['job'].index[top_k_job_indices].tolist()\n","\n","    return top_k_job_ids\n"]},{"cell_type":"markdown","source":["# create empty graph"],"metadata":{"id":"oTMXQnckRHdw"}},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uWMRY4iAtbbJ","executionInfo":{"status":"ok","timestamp":1717085796865,"user_tz":-60,"elapsed":24315,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}},"outputId":"cb7d5371-48d2-4707-8589-68397b22e32c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["data=create_empty_graph()\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WpkIGbofRJLO","executionInfo":{"status":"ok","timestamp":1717085800763,"user_tz":-60,"elapsed":10,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}},"outputId":"9a8d8a78-d892-4145-f678-6a9b5cebf0d4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["HeteroData(\n","  user={\n","    num_nodes=0,\n","    x=[0, 768],\n","    topic=[0],\n","    index=[0],\n","  },\n","  job={\n","    num_nodes=0,\n","    x=[0, 768],\n","    topic=[0],\n","    index=[0],\n","  },\n","  (user, applies, job)={\n","    edge_index=[2, 0],\n","    edge_label=[0],\n","  },\n","  (user, similar_U, user)={ edge_index=[2, 0] },\n","  (job, similar_J, job)={ edge_index=[2, 0] },\n","  (job, rev_applies, user)={\n","    edge_index=[2, 0],\n","    edge_label=[0],\n","  }\n",")\n"]}]},{"cell_type":"code","source":["torch.save(data, '/content/drive/MyDrive/data/graph/web_graph.pt')"],"metadata":{"id":"OS934NX5RbYT","executionInfo":{"status":"ok","timestamp":1717085806145,"user_tz":-60,"elapsed":229,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["data=torch.load('/content/drive/MyDrive/data/graph/web_graph.pt')\n","print(data.metadata())"],"metadata":{"id":"WNPgCsioXpNp","executionInfo":{"status":"ok","timestamp":1717087167041,"user_tz":-60,"elapsed":627,"user":{"displayName":"PFE Licence","userId":"06306307624443497936"}},"outputId":"c5c681f5-9da2-42b8-9eca-139192878c38","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["(['user', 'job'], [('user', 'applies', 'job'), ('user', 'similar_U', 'user'), ('job', 'similar_J', 'job'), ('job', 'rev_applies', 'user')])\n"]}]},{"cell_type":"code","source":["data"],"metadata":{"id":"UZKr-fUHTYLL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C65DmZgws7LX"},"source":["# test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4O7LlFqtDbH"},"outputs":[],"source":["import torch\n","from torch_geometric.nn import SAGEConv, to_hetero"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AVNFUPoXs8a0"},"outputs":[],"source":["class GCN_2(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_channels):\n","        super().__init__()\n","        self.conv1 = SAGEConv(input_dim, hidden_channels)\n","        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index).relu()\n","        x = self.conv2(x, edge_index)\n","        return x\n","\n","class CosineSimilarityDecoder(torch.nn.Module):\n","    def forward(self, x_dict, edge_label_index):\n","        x_src = x_dict['user'][edge_label_index[0]]\n","        x_dst = x_dict['job'][edge_label_index[1]]\n","        return torch.cosine_similarity(x_src, x_dst, dim=1)\n","\n","\n","class Model(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_channels):\n","        super().__init__()\n","        self.encoder = GCN_2(input_dim, hidden_channels)\n","        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n","        self.decoder = CosineSimilarityDecoder()\n","\n","    def forward(self, x_dict, edge_index_dict, edge_label_index):\n","        x_dict = self.encoder(x_dict, edge_index_dict)\n","        cosine_similarity = self.decoder(x_dict, edge_label_index)\n","        return cosine_similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oBIz0pc4trH-"},"outputs":[],"source":["model=torch.load('/content/drive/MyDrive/models/Best_model.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPvdS5JissBN"},"outputs":[],"source":["data = create_empty_graph()\n","\n","add_node_user(data, 0, \"text\", 1)\n","add_node_user(data, 1, \"text\", 2)\n","add_node_user(data, 2, \"text\", 3)\n","add_node_job(data, 0, \"text\", 1)\n","add_node_job(data, 1, \"text\", 2)\n","add_node_job(data, 2, \"text\", 3)\n","add_edge_app(data, 0, 0)\n","add_edge_app(data, 1, 1)\n","add_edge_app(data, 2, 2)\n","\n","print(data)\n","\n","user_id = 0\n","k = 3\n","top_k_job_ids = recommend_top_k(user_id, data, model, k)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IG4PV-5xt6yt"},"outputs":[],"source":["print(top_k_job_ids)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1W72YjpPfUvwX1OAenvarsOc88moRFeYS","timestamp":1716881092232}],"collapsed_sections":["psn7MZqCKACe","8aqRXaQpMODX","kj-YciHk6U5p"],"toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}